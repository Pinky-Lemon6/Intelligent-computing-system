# 任务1
## 实验目的
* 实现`pairwise_distances`函数，计算两个向量之间的$l_2$距离
## 实验环境
* `Python` 3.11.9
* `numpy` 1.26.4
## 实验原理
* $d_2(X, Y)=\sqrt{\sum_{i=1}^n(x_i-y_i)^2}$
## 实验步骤
* 导入所需的库
```python
import numpy as np
```
* 实现函数
    * 定义 pairwise_distances 函数，接受两个输入参数 A 和 B，并根据上述公式计算行间距离。
    * 遍历 A 和 B 的每一行，计算每一行之间的差异并累加。
    * 对累加结果开根号得出向量的$l_2$距离
```python
def pairwise_distances(A, B):
    """return the matrix of distances between the rows of A and the rows of B
    params: A: np.ndarry A.shape = (-1); B: np.ndarry B.shape = (-1)
    A.shape[0] = B.shape[0]"""
    ret = 0
    for i in range(A.shape[0]):
        ret += np.square(A[i]-B[i])
    return np.sqrt(ret)
```
## 实验结果
* 与numpy自带的$l_2$距离计算函数做对比
```python
def pairwise_distances_v1(A, B):
    """直接调用numpy"""
    return np.linalg.norm(A - B)

def main():
    np.random.seed(123)
    dim = 128

    print("*"*50) # task1
    A, B = np.random.rand(dim), np.random.rand(dim)
    l2_AB = pairwise_distances(A, B)
    l2_AB_ = pairwise_distances_v1(A, B)

    # print(f"A: {A}\nB: {B}")
    print(f"L2_AB: {l2_AB}")
    print(f"L2_AB_: {l2_AB_}")

if __name__ == "__main__":
    main()
```
* 输出结果
```cmd
**************************************************
L2_AB: 4.3234316550288545
L2_AB_: 4.3234316550288545
```

## 结果分析
* 输出结果与numpy库计算结果一致
## 总结与改进
* 无

# 任务2
## 实验目的
* 实现`knn_search`函数，该函数针对一组`query`查询返回在$L_2$距离下`database`中的最近邻
## 实验环境
* `Python` 3.11.9
* `numpy` 1.26.4
* `sklearn` 1.5.1
* `kneed` 0.8.5
## 实验原理
* 在接收到数据库`database`时，首先对`database`中的向量做`kmeans`聚类
    * 首先从`database`中抽取小样本(这里取1024)进行`kmeans`聚类，用于确定最佳聚类数`n_cluster`
    * 使用`kmeans`将`database`中的向量分为`n_cluster`组
* 查询时，先计算`query`与各聚类中心点的距离，定位到距离`query`最近的类
* 对距离`query`最近的类中的每个向量，分别计算其与query的距离，并按照从小到大的顺序选出距离最近的10条向量
## 实验步骤
* 导入所需的库
```python
from sklearn.cluster import KMeans
import numpy as np
import random
import warnings
warnings.filterwarnings('ignore')
from kneed import KneeLocator
```
* 使用多个多元正态分布生成模拟`database`
```python
def generate_vectors_v1(dim, n, n_clusters=4):
    """使用多元正态生成n个维数为dim模长为1的向量"""
    means = np.random.rand(n_clusters, dim)
    stddev = np.ones(dim)
    cluster_size = int(n/n_clusters)
    
    ret = np.zeros((n, dim))
    for i in range(n):
        cluster = i//cluster_size
        ret[i] += np.random.normal(means[cluster], stddev, size=(dim))
    np.random.shuffle(ret)
    
    ret /= np.linalg.norm(ret, axis=1, keepdims=True)
    return ret
```
* 对database进行聚类
    * `get_best_k`函数
        * 函数接收一个形状为$(length, dim)$的抽样向量组，其中$length$为向量数量
        * 函数在$[2, int(log_2length)]$的区间上通过循环的方式寻找最佳聚类数，具体实现方法为记录每次`kmeans`聚类后的SSE损失，并通过`KneeLocator`使用肘部法确定最佳聚类数
        * 函数返回最佳聚类数的值`best_k`
    * `cluster`函数
        * 函数接收形状为$(n, dim)$的数据库矩阵`database`
        * 函数首先通过随机采样并调用`get_best_k`函数计算出最佳聚类数`n_cluster`
        * 之后使用`kmeans`聚类将`database`分为多组
        * 函数返回值: `lebals`是一个长度为`n`的list，`centers`是一个长度为`nclusters`的矩阵
```python
def get_best_k(database):
    length = database.shape[0]
    min = 2
    max = np.log2(length)
    losses = []
    sum = 0
    for i in range(int(min), int(max+1)):
        kmeans = KMeans(n_clusters=i)
        kmeans.fit(database)
        sum += kmeans.inertia_
        losses.append(kmeans.inertia_)
    knee = KneeLocator(range(int(min), int(max+1)), losses, curve='convex', direction='decreasing')
    if knee.knee is not None:
        best_k = int(knee.knee)
    else:
        best_k = int(max+1)
    return best_k

def cluster(database):
    """返回值: lebals是一个长度为database.shape[0]的list
    centers是一个长度为nclusters的矩阵"""
    # 先抽小样本测试聚为几类
    idxs = random_sample(database.shape[0], 1024)
    tmp = database[idxs]
    n_clusters = get_best_k(tmp)
    # 聚类
    kmeans = KMeans(n_clusters)
    kmeans.fit(database)
    labels = kmeans.predict(database)
    centers = kmeans.cluster_centers_
    return labels, centers
```
* 查找query的最近邻
    * `knn_search`函数
        * 函数接收参数
            * `query`: 查询向量
            * `database`: 数据库向量组
            * `idxs`: `cluster`函数的返回值`idxs`
            * `centers`: `cluster`函数的返回值`centers`
            * `k`: 需要查询的条数
        * 函数首先计算`query`与各个中心点的$l_2$距离，并选出最近的类
        * 对于最近的类中的所有向量，分别计算与`query`的距离，并选出topk
        * 函数返回值为距离`query`最近的k条向量
```python
def knn_search(queries, database, idxs, centers, k):
    """the k nearest database vector indices for each query vector"""
    l2 = np.array([pairwise_distances_v1(i, queries.reshape(-1, 1)).reshape(-1, ) 
          for i in centers]).reshape(-1,)
    best_cluster = np.argmin(l2)
    database = database[idxs == best_cluster]
    # 暴搜找topk
    l2 = np.array([pairwise_distances_v1(i, queries.reshape(-1, 1)).reshape(-1, ) 
          for i in database]).reshape(-1,)
    
    sorted_indices = np.argsort(l2)[::-1]
    top_10_indices = sorted_indices[: k]

    return database[top_10_indices]
```
## 实验结果
* 首先通过辅助函数生成数据库`database`
    * `generate_vectors_v1`函数
        * 接收参数
            * `dim`: 向量维数
            * `n`: database的长度
            * `n_clusters`: 由几个多元正态分布来生成数据
        * 函数在生成`database`完成了对向量模长的归一化
    
```python
def generate_vectors_v1(dim, n, n_clusters=4):
    """使用多元正态生成n个维数为dim模长为1的向量"""
    means = np.random.rand(n_clusters, dim)
    stddev = np.ones(dim)
    cluster_size = int(n/n_clusters)
    
    ret = np.zeros((n, dim))
    for i in range(n):
        cluster = i//cluster_size
        ret[i] += np.random.normal(means[cluster], stddev, size=(dim))
    np.random.shuffle(ret)
    
    ret /= np.linalg.norm(ret, axis=1, keepdims=True)
    return ret

def main():
    np.random.seed(123)
    n = 2**14
    dim = 128
    topk = 3
    A, B = np.random.rand(dim), np.random.rand(dim)
    print("*"*50) # task2
    database = generate_vectors_v1(dim, n, n_clusters=8)
    # print(database.shape)
    idxs, centers = cluster(database)
    knn_A = knn_search(A, database, idxs, centers, topk)
    knn_B = knn_search(B, database, idxs, centers, topk)
    print(f"knn_A:")
    for i in knn_A:
        print(i)
    print(f"knn_B:")
    for i in knn_B:
        print(i)
```
* 输出结果
```cmd
**************************************************
knn_A:
[-0.05329723  0.01134575  0.1133592   0.01649666  0.07209187 -0.12221555
  0.05722067 -0.03771103  0.02608524  0.00947691 -0.09283475  0.04266271
  0.04630391  0.13885832 -0.16970505 -0.0172305   0.06272606  0.16300347
 -0.02678554 -0.07341581 -0.07799498  0.11241     0.1356872   0.09505011
 -0.09190425 -0.00937953 -0.08865554 -0.07313792 -0.04165029 -0.00120365
 -0.06403221 -0.00611048  0.08978458  0.05610496 -0.14250241 -0.09261567
  0.06115109 -0.10129616 -0.00051201  0.21589788  0.0872781   0.0329919
  0.00208488  0.00731919  0.04101394  0.06621933  0.06142353  0.04010203
  0.07448425  0.03996217 -0.07562774  0.01266545  0.10445993  0.17710372
  0.08497364 -0.01369024 -0.01242415  0.02159616 -0.03825121  0.06952103
 -0.01474506  0.06950794  0.02612297 -0.07775348  0.01031866 -0.1498689
 -0.06181334  0.14936168  0.13321294  0.0504995   0.18560122 -0.02388773
 -0.13398594 -0.10458731  0.10884229 -0.07460618 -0.00418382  0.08473662
  0.13630055  0.05515855  0.10357242  0.15164808  0.06087526 -0.10357854
 -0.10224499  0.00681975 -0.04195863  0.08019505 -0.00186315  0.02512178
  0.07373056 -0.01685592 -0.08708611 -0.0212752   0.09751662  0.11411341
  0.00852246 -0.14985378  0.06604313  0.21889754  0.04890512  0.02299377
 -0.10431434  0.16579253 -0.00289991 -0.02511252  0.05107122  0.10288065
  0.00814277 -0.00880446 -0.03279197  0.02154724  0.02189754  0.17947212
  0.02065604  0.09742036 -0.10816075  0.14162023 -0.02983479  0.08778774
  0.13349227  0.06546882 -0.08494591  0.10233992  0.17609535  0.00243682
 -0.12779974  0.00320685]
[-0.16558465  0.08826422  0.04538062  0.12406906 -0.02990493 -0.02309976
  0.06343987 -0.02775676 -0.00963899  0.07566615  0.02448327  0.07421619
 -0.10558217 -0.00462374  0.04926799 -0.06446705 -0.00556988  0.07188374
  0.03717988  0.13524333 -0.055933    0.06317799  0.05347886  0.05441365
  0.00090573  0.02980059  0.02086336 -0.03439098  0.09343089  0.08025136
 -0.09786496  0.01590765  0.08458821  0.0478546   0.01813851  0.09525406
 -0.07444736 -0.14726832  0.04250617  0.03364073  0.11532971  0.10931478
 -0.11488539 -0.01926356  0.01580942  0.03982056 -0.10414151  0.07840028
 -0.0349952  -0.04700461  0.01567561 -0.03859993  0.09800994 -0.00901703
  0.10956386 -0.11841752  0.20175476  0.21011471  0.05918111  0.12816087
  0.06924744  0.05180649  0.06651293 -0.08157542  0.11032862  0.08323276
  0.00207962  0.04283051  0.1754553  -0.03179966  0.09996258  0.02667769
  0.04503931 -0.04135692  0.07049624  0.13898288  0.0840597   0.17115906
 -0.11790721 -0.14866999 -0.06165417 -0.11085517  0.15378927  0.06331079
  0.0380326   0.00140631 -0.09402502  0.03248621  0.00571072  0.00673512
  0.02081953 -0.04051761  0.03367196  0.01750139 -0.04457299  0.04616566
 -0.00787186 -0.04287365  0.12019553 -0.0013684   0.06190375  0.02856329
  0.15578339  0.20124855  0.0854571   0.17939415 -0.00153782  0.0642986
 -0.02634712  0.05711243 -0.04088601  0.0337286  -0.18411377  0.27061059
 -0.04904423  0.0243967  -0.12281323  0.16200235 -0.12840493  0.0186209
 -0.03166996  0.03433352 -0.0193811  -0.00246869 -0.17900595 -0.00845485
 -0.08658375  0.04446129]
[-0.09989978 -0.06665974  0.14067518  0.03139652 -0.01993932  0.0671568
  0.13245757  0.15118589  0.20039913  0.03629272  0.12201758 -0.07626723
 -0.09166965  0.15635718  0.08905553 -0.01296456  0.01998306 -0.01504657
  0.04494403 -0.05231919  0.08859053  0.03592453 -0.03801763  0.06211317
  0.1605469   0.14983756  0.09788292  0.04799047  0.06864928 -0.12278295
 -0.14272903 -0.17858625 -0.05307802 -0.08387706  0.01903065  0.0069065
  0.07643045  0.11938749  0.04430821  0.08854523  0.03936761 -0.06992556
 -0.02153631  0.05296581 -0.03620132  0.11943658 -0.05947311 -0.01186525
 -0.13048393  0.02383739  0.05940938 -0.08005062 -0.06805449  0.01095879
 -0.04429049  0.0149118  -0.08666    -0.01190191  0.14877558  0.02733282
  0.00427418  0.02372702 -0.01542744 -0.0948146   0.15290315 -0.02076869
  0.1213925   0.20260462 -0.11996527  0.10067556  0.04248933  0.07592945
 -0.01709648  0.0136454   0.07532714 -0.03451346 -0.16281468  0.02160025
 -0.06370995  0.01120343 -0.06169544  0.1288609   0.07870144 -0.03612245
 -0.09865875 -0.00480579  0.17103121  0.18869758 -0.02221177 -0.12763279
 -0.1302084   0.01721308 -0.09220459 -0.04445066  0.07485838  0.03154959
  0.04226018  0.01620361 -0.00493973  0.07477551 -0.00641154  0.1356003
 -0.04491306  0.03067696  0.1462637   0.09272054  0.17189758 -0.00710543
  0.03941421  0.05708554  0.04152677  0.09095363  0.01839084 -0.03944153
 -0.053746    0.05966777 -0.05840702  0.0391297   0.09077101  0.10766828
 -0.0507031   0.08855277  0.06823308  0.09025485  0.098439    0.15243503
 -0.09039855  0.12540329]
knn_B:
[-0.05329723  0.01134575  0.1133592   0.01649666  0.07209187 -0.12221555
  0.05722067 -0.03771103  0.02608524  0.00947691 -0.09283475  0.04266271
  0.04630391  0.13885832 -0.16970505 -0.0172305   0.06272606  0.16300347
 -0.02678554 -0.07341581 -0.07799498  0.11241     0.1356872   0.09505011
 -0.09190425 -0.00937953 -0.08865554 -0.07313792 -0.04165029 -0.00120365
 -0.06403221 -0.00611048  0.08978458  0.05610496 -0.14250241 -0.09261567
  0.06115109 -0.10129616 -0.00051201  0.21589788  0.0872781   0.0329919
  0.00208488  0.00731919  0.04101394  0.06621933  0.06142353  0.04010203
  0.07448425  0.03996217 -0.07562774  0.01266545  0.10445993  0.17710372
  0.08497364 -0.01369024 -0.01242415  0.02159616 -0.03825121  0.06952103
 -0.01474506  0.06950794  0.02612297 -0.07775348  0.01031866 -0.1498689
 -0.06181334  0.14936168  0.13321294  0.0504995   0.18560122 -0.02388773
 -0.13398594 -0.10458731  0.10884229 -0.07460618 -0.00418382  0.08473662
  0.13630055  0.05515855  0.10357242  0.15164808  0.06087526 -0.10357854
 -0.10224499  0.00681975 -0.04195863  0.08019505 -0.00186315  0.02512178
  0.07373056 -0.01685592 -0.08708611 -0.0212752   0.09751662  0.11411341
  0.00852246 -0.14985378  0.06604313  0.21889754  0.04890512  0.02299377
 -0.10431434  0.16579253 -0.00289991 -0.02511252  0.05107122  0.10288065
  0.00814277 -0.00880446 -0.03279197  0.02154724  0.02189754  0.17947212
  0.02065604  0.09742036 -0.10816075  0.14162023 -0.02983479  0.08778774
  0.13349227  0.06546882 -0.08494591  0.10233992  0.17609535  0.00243682
 -0.12779974  0.00320685]
[-0.16558465  0.08826422  0.04538062  0.12406906 -0.02990493 -0.02309976
  0.06343987 -0.02775676 -0.00963899  0.07566615  0.02448327  0.07421619
 -0.10558217 -0.00462374  0.04926799 -0.06446705 -0.00556988  0.07188374
  0.03717988  0.13524333 -0.055933    0.06317799  0.05347886  0.05441365
  0.00090573  0.02980059  0.02086336 -0.03439098  0.09343089  0.08025136
 -0.09786496  0.01590765  0.08458821  0.0478546   0.01813851  0.09525406
 -0.07444736 -0.14726832  0.04250617  0.03364073  0.11532971  0.10931478
 -0.11488539 -0.01926356  0.01580942  0.03982056 -0.10414151  0.07840028
 -0.0349952  -0.04700461  0.01567561 -0.03859993  0.09800994 -0.00901703
  0.10956386 -0.11841752  0.20175476  0.21011471  0.05918111  0.12816087
  0.06924744  0.05180649  0.06651293 -0.08157542  0.11032862  0.08323276
  0.00207962  0.04283051  0.1754553  -0.03179966  0.09996258  0.02667769
  0.04503931 -0.04135692  0.07049624  0.13898288  0.0840597   0.17115906
 -0.11790721 -0.14866999 -0.06165417 -0.11085517  0.15378927  0.06331079
  0.0380326   0.00140631 -0.09402502  0.03248621  0.00571072  0.00673512
  0.02081953 -0.04051761  0.03367196  0.01750139 -0.04457299  0.04616566
 -0.00787186 -0.04287365  0.12019553 -0.0013684   0.06190375  0.02856329
  0.15578339  0.20124855  0.0854571   0.17939415 -0.00153782  0.0642986
 -0.02634712  0.05711243 -0.04088601  0.0337286  -0.18411377  0.27061059
 -0.04904423  0.0243967  -0.12281323  0.16200235 -0.12840493  0.0186209
 -0.03166996  0.03433352 -0.0193811  -0.00246869 -0.17900595 -0.00845485
 -0.08658375  0.04446129]
[-0.09989978 -0.06665974  0.14067518  0.03139652 -0.01993932  0.0671568
  0.13245757  0.15118589  0.20039913  0.03629272  0.12201758 -0.07626723
 -0.09166965  0.15635718  0.08905553 -0.01296456  0.01998306 -0.01504657
  0.04494403 -0.05231919  0.08859053  0.03592453 -0.03801763  0.06211317
  0.1605469   0.14983756  0.09788292  0.04799047  0.06864928 -0.12278295
 -0.14272903 -0.17858625 -0.05307802 -0.08387706  0.01903065  0.0069065
  0.07643045  0.11938749  0.04430821  0.08854523  0.03936761 -0.06992556
 -0.02153631  0.05296581 -0.03620132  0.11943658 -0.05947311 -0.01186525
 -0.13048393  0.02383739  0.05940938 -0.08005062 -0.06805449  0.01095879
 -0.04429049  0.0149118  -0.08666    -0.01190191  0.14877558  0.02733282
  0.00427418  0.02372702 -0.01542744 -0.0948146   0.15290315 -0.02076869
  0.1213925   0.20260462 -0.11996527  0.10067556  0.04248933  0.07592945
 -0.01709648  0.0136454   0.07532714 -0.03451346 -0.16281468  0.02160025
 -0.06370995  0.01120343 -0.06169544  0.1288609   0.07870144 -0.03612245
 -0.09865875 -0.00480579  0.17103121  0.18869758 -0.02221177 -0.12763279
 -0.1302084   0.01721308 -0.09220459 -0.04445066  0.07485838  0.03154959
  0.04226018  0.01620361 -0.00493973  0.07477551 -0.00641154  0.1356003
 -0.04491306  0.03067696  0.1462637   0.09272054  0.17189758 -0.00710543
  0.03941421  0.05708554  0.04152677  0.09095363  0.01839084 -0.03944153
 -0.053746    0.05966777 -0.05840702  0.0391297   0.09077101  0.10766828
 -0.0507031   0.08855277  0.06823308  0.09025485  0.098439    0.15243503
 -0.09039855  0.12540329]
```
## 结果分析
* 由`kmeans`方法简化计算得出的最近n个向量未必是最优的结果
* 本实验通过随机抽样的方式确定最佳聚类数，未必一定准确，但优点是不需要事先知道最佳聚类数，可以自动化完成，实验过程中通过调整生成数据的`n_cluster`参数发现，在多元正态分布均值小于1，方差等于1的情况下可以准确识别最佳的聚类数量
## 总结与改进
* 改进方案
    * 可以从与`query`最近的c个类中进行检索，这里因为实验分的类数量较少，就只选择了最近的一个类来实现
    * 类内暴力搜索的排序策略可以通过堆排序来优化性能，这里直接调用了`numpy`的排序函数，是因为`numpy`中的排序函数是通过c语言实现的，速度更快，使用python语言编写的堆排函数的性能未必能够超越封装好的排序函数